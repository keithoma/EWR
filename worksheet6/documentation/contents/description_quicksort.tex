\section{Quicksort}
\subsection{Intuition and Description}
Quicksort is a divide-and-conquere, recursive sorting algorithm.\cite[p.~145]{bib:introductiontoalgorithms} Informally speaking, quicksort first chooses a pivot element (in our case, the last element of the list\footnote{For the purpose of this paper, we define a list to be an ordered set for which an order relation such as \(<\) is defined. In terms of computer science, this equates to an array-like data type (in Python this would be a list) with elements which can be compared. An concrete example would be \((0, 1, 2, 3)\) which is incidentally already sorted according to the smaller relation, \(<\).} is chosen as the pivot\footnote{There are more sophisticated ways to choose the pivot. See section XXX for more information.}), then compares every element of the given list to the pivot placing elements smaller than the pivot to the left and every other element to the right. This partitions the list into two. The initial pivot is placed between the two partitions. Note that the pivot is correctly placed since every element smaller than the pivot are in the left partition. Then, the quicksort algorithm is applied to both partitions. The recursion is broken if the current partition only contains zero or one elements.

More formally, we present the pseudocode for the procedure.

\begin{lstlisting}
def partition(_partition, _low, _high):
    i = _low - 1

    # here, we choose the pivot as the far right element of the
    # partition
    pivot = _partition[_high]

    # from line 12 to line 17 we move every element smaller than 
    # the pivot to the left and every other element to the right
    # then we place the pivot in the middle of the two partitions
    for j in range(_low, _high):
        if _partition[j] < pivot:
            ++i
            _partition[i], _partition[j] = _partition[j], 
                                           _partition[i]
    ++i
    _partition[i], _partition[j] = _partition[j], _partition[i]

    return i

def sort_range(_partition, _low, _high):
    if _low < _high:
        pivot_index = partition(_partition)

        if pivot_index > 0:
            sort_range(_partition, _low, pivot_index - 1)
        sort_range(_partition, pivot_index + 1, _high)


# entry point of the algorithm
def quicksort(_list):
    list_length = len(_list)
    sort_range(_list, 0, list_length - 1)

\end{lstlisting}

\input{contents/worked_example_one.tex}

\subsection{Complexity}
%The complexity of quicksort highly depends on the choice of the pivot. We set the pivot naïvely to be the last element in the partition which is not optimal. The best selection of the pivot is the median of the list since this would leave half of the elements on the left and the other half on the right of the pivot splitting the list into two equally large partitions.

%Therefore, we call a pivot \textit{good enough} if it lies in the center half of the list i.e. larger than the smallest 1/4, but smaller than the largest 3/4. In the worst case scenario for a good enough pivot, the larger partition has the 3/4 of the size of the intial list. Following the recursion, we get partitions in sizes of
%\begin{equation*}
%    n, \frac{3}{4} n, \left(\frac{3}{4}\right)^2 n, \dots, 1 \text{.}
%\end{equation*}
%Let \(h_g\) be the height of the quicksort partition tree. Then for \(\left(\frac{3}{4}\right)^{h_g} n = 1\) we have \(\)

The complexity of quicksort highly depends on the choice of the pivot. We have set the pivot naïvely to be the last element in the partition which is not optimal. In general, a median pivot is the most desireble since it splits the list into two most possible even partitions.

The worst case for quicksort is when every recursion creates a partition of maximum length. This results in the complexity of \(O(n^2)\) (same as selection sort). While a very rare case, this happens most interestingly when the list is already sorted due to the nature how we pick our pivot.\cite[p.~137]{bib:thealgorithmdesignmanual}

If every split produces partition with equal length (or length differing exactly by one), the algorithm achives the best case performance of \(O(n \ln(n))\). The average case of quicksort is closer to the best case than to the worst case. Indeed, the average case running time of quicksort is again \(O(n \ln(n))\).\cite[p.~150]{bib:introductiontoalgorithms}

Quicksort is not stable. We will show this with an example. Consider a list \((2, 2^{*}, 1)\). After choosing \(1\) as the initial pivot, the list is sorted almost immediately into \((1, 2^{*}, 2)\). \(2\) and \(2^{*}\) do not retain their order, hence quicksort is not stable.